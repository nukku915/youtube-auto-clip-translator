#!/usr/bin/env python3
"""
é¸æ‰‹ã®éŸ³å£°ã‚’è‡ªå‹•åé›†ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°ã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
    # ç‰¹å®šã®é¸æ‰‹ã®éŸ³å£°ã‚’åé›†ï¼ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å‹•ç”»ã‹ã‚‰ - éæ¨å¥¨ï¼‰
    python auto_collect_voice.py Faker

    # ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‹ã‚‰è‡ªå‹•åé›†ï¼ˆæ¨å¥¨ï¼‰
    python auto_collect_voice.py --team-voice-auto T1

    # ç‰¹å®šé¸æ‰‹ã®ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹ã‹ã‚‰åé›†
    python auto_collect_voice.py --team-voice-auto T1 --player Faker

    # ãƒãƒ¼ãƒ å…¨å“¡ã®éŸ³å£°ã‚’åé›†
    python auto_collect_voice.py --team T1

    # å…¨é¸æ‰‹ã®éŸ³å£°ã‚’åé›†
    python auto_collect_voice.py --all

    # åé›†ã®ã¿ï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°ãªã—ï¼‰
    python auto_collect_voice.py Faker --collect-only
"""

import os
import sys
import json
import argparse
import subprocess
import numpy as np
import torchaudio
import torch
import whisper
from datetime import datetime
from pathlib import Path
import yt_dlp
from speechbrain.inference.speaker import EncoderClassifier

# è¨­å®š
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
EMBEDDINGS_DIR = os.path.join(BASE_DIR, 'data/speaker_embeddings_v2')
BACKUP_DIR = os.path.join(BASE_DIR, 'data/embeddings_backup')
CACHE_DIR = os.path.join(BASE_DIR, 'data/speechbrain_cache')
COLLECT_DIR = os.path.join(BASE_DIR, 'downloads/collected_voices')
DB_PATH = os.path.join(BASE_DIR, 'data/speaker_database.json')
BACKUP_HISTORY_PATH = os.path.join(BASE_DIR, 'data/backup_history.json')

# é¸æ‰‹ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆéŸ“å›½èªåã€è‹±èªåã€ãƒ‹ãƒƒã‚¯ãƒãƒ¼ãƒ ï¼‰
PLAYER_SEARCH_KEYWORDS = {
    # T1
    'faker': ['Faker interview', 'T1 Faker', 'í˜ì´ì»¤ ì¸í„°ë·°', 'Faker voice'],
    'keria': ['Keria interview', 'T1 Keria', 'ì¼€ë¦¬ì•„ ì¸í„°ë·°'],
    'oner': ['Oner interview', 'T1 Oner', 'ì˜¤ë„ˆ ì¸í„°ë·°'],
    'peyz': ['Peyz interview', 'T1 Peyz', 'í˜ì´ì¦ˆ ì¸í„°ë·°'],
    'doran': ['Doran interview', 'T1 Doran', 'ë„ë€ ì¸í„°ë·°'],

    # GenG
    'chovy': ['Chovy interview', 'GenG Chovy', 'ìµ¸ë¹„ ì¸í„°ë·°'],
    'canyon': ['Canyon interview', 'GenG Canyon', 'ìºë‹ˆì–¸ ì¸í„°ë·°'],
    'ruler': ['Ruler interview', 'GenG Ruler', 'ë£°ëŸ¬ ì¸í„°ë·°'],
    'kiin': ['Kiin interview', 'GenG Kiin', 'ê¸°ì¸ ì¸í„°ë·°'],
    'duro': ['Duro interview', 'GenG Duro', 'ë“€ë¡œ ì¸í„°ë·°'],

    # HLE
    'zeus': ['Zeus interview', 'HLE Zeus', 'ì œìš°ìŠ¤ ì¸í„°ë·°', 'T1 Zeus'],
    'peanut': ['Peanut interview', 'HLE Peanut', 'í”¼ë„› ì¸í„°ë·°'],
    'zeka': ['Zeka interview', 'HLE Zeka', 'ì œì¹´ ì¸í„°ë·°'],
    'gumayusi': ['Gumayusi interview', 'HLE Gumayusi', 'êµ¬ë§ˆìœ ì‹œ ì¸í„°ë·°', 'T1 Gumayusi'],
    'viper': ['Viper interview', 'HLE Viper', 'ë°”ì´í¼ ì¸í„°ë·°'],
    'delight': ['Delight interview', 'HLE Delight', 'ë”œë¼ì´íŠ¸ ì¸í„°ë·°'],

    # DK
    'showmaker': ['ShowMaker interview', 'DK ShowMaker', 'ì‡¼ë©”ì´ì»¤ ì¸í„°ë·°'],
    'lucid': ['Lucid interview', 'DK Lucid', 'ë£¨ì‹œë“œ ì¸í„°ë·°'],
    'siwoo': ['Siwoo interview', 'DK Siwoo', 'ì‹œìš° ì¸í„°ë·°'],

    # KT
    'bdd': ['Bdd interview', 'KT Bdd', 'ë¹„ë””ë”” ì¸í„°ë·°'],
    'cuzz': ['Cuzz interview', 'KT Cuzz', 'ì»¤ì¦ˆ ì¸í„°ë·°'],
    'aiming': ['Aiming interview', 'KT Aiming', 'ì—ì´ë° ì¸í„°ë·°'],
}

# ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã®æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
TEAM_VOICE_KEYWORDS = {
    'T1': ['T1 team voice', 'T1 comms', 'T1 íŒ€ ë³´ì´ìŠ¤', 'T1 voice comms', 'T1 LCK íŒ€ ë³´ì´ìŠ¤'],
    'GenG': ['GenG team voice', 'GenG comms', 'GenG íŒ€ ë³´ì´ìŠ¤', 'Gen.G LCK íŒ€ ë³´ì´ìŠ¤'],
    'HLE': ['HLE team voice', 'Hanwha team voice', 'HLE comms', 'HLE LCK íŒ€ ë³´ì´ìŠ¤'],
    'DK': ['DK team voice', 'Dplus KIA comms', 'DK íŒ€ ë³´ì´ìŠ¤', 'DK LCK íŒ€ ë³´ì´ìŠ¤'],
    'KT': ['KT team voice', 'KT Rolster comms', 'KT íŒ€ ë³´ì´ìŠ¤', 'KT LCK íŒ€ ë³´ì´ìŠ¤'],
}

# é¸æ‰‹åã®éŸ“å›½èªãƒãƒƒãƒ”ãƒ³ã‚°
PLAYER_NAME_KOREAN = {
    # T1
    'faker': ['í˜ì´ì»¤', 'Faker', 'faker'],
    'keria': ['ì¼€ë¦¬ì•„', 'Keria', 'keria'],
    'oner': ['ì˜¤ë„ˆ', 'Oner', 'oner'],
    'peyz': ['í˜ì´ì¦ˆ', 'Peyz', 'peyz'],
    'doran': ['ë„ë€', 'Doran', 'doran'],
    # GenG
    'chovy': ['ìµ¸ë¹„', 'Chovy', 'chovy'],
    'canyon': ['ìºë…„', 'ìºë‹ˆì–¸', 'Canyon', 'canyon'],
    'ruler': ['ë£°ëŸ¬', 'Ruler', 'ruler'],
    'kiin': ['ê¸°ì¸', 'Kiin', 'kiin'],
    'duro': ['ë“€ë¡œ', 'Duro', 'duro'],
    'lehends': ['ë ˆí—¨ì¦ˆ', 'Lehends', 'lehends'],
    # HLE
    'zeus': ['ì œìš°ìŠ¤', 'Zeus', 'zeus'],
    'peanut': ['í”¼ë„›', 'Peanut', 'peanut'],
    'zeka': ['ì œì¹´', 'Zeka', 'zeka'],
    'gumayusi': ['êµ¬ë§ˆìœ ì‹œ', 'Gumayusi', 'gumayusi'],
    'viper': ['ë°”ì´í¼', 'Viper', 'viper'],
    'delight': ['ë”œë¼ì´íŠ¸', 'Delight', 'delight'],
    'kanavi': ['ì¹´ë‚˜ë¹„', 'Kanavi', 'kanavi'],
    # DK
    'showmaker': ['ì‡¼ë©”ì´ì»¤', 'ShowMaker', 'showmaker', 'Showmaker'],
    'lucid': ['ë£¨ì‹œë“œ', 'Lucid', 'lucid'],
    'siwoo': ['ì‹œìš°', 'Siwoo', 'siwoo'],
    'smash': ['ìŠ¤ë§¤ì‰¬', 'Smash', 'smash'],
    'career': ['ì»¤ë¦¬ì–´', 'Career', 'career'],
    'vicla': ['ë¹…ë¼', 'VicLa', 'vicla'],
    # KT
    'bdd': ['ë¹„ë””ë””', 'Bdd', 'bdd', 'BDD'],
    'cuzz': ['ì»¤ì¦ˆ', 'Cuzz', 'cuzz'],
    'aiming': ['ì—ì´ë°', 'Aiming', 'aiming'],
    'perfect': ['í¼í™íŠ¸', 'PerfecT', 'perfect', 'Perfect'],
    'ghost': ['ê³ ìŠ¤íŠ¸', 'Ghost', 'ghost'],
}

import re

# pyannote-audioã®è©±è€…ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
try:
    from pyannote.audio import Pipeline
    PYANNOTE_AVAILABLE = True
except ImportError:
    PYANNOTE_AVAILABLE = False


def load_database():
    """é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èª­ã¿è¾¼ã¿"""
    with open(DB_PATH, 'r') as f:
        return json.load(f)


def save_database(db):
    """é¸æ‰‹ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜"""
    db['updated'] = datetime.now().isoformat()
    with open(DB_PATH, 'w') as f:
        json.dump(db, f, indent=2, ensure_ascii=False)


def load_backup_history() -> dict:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´ã‚’èª­ã¿è¾¼ã¿"""
    if os.path.exists(BACKUP_HISTORY_PATH):
        with open(BACKUP_HISTORY_PATH, 'r') as f:
            return json.load(f)
    return {'backups': [], 'max_backups': 10}


def save_backup_history(history: dict):
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å±¥æ­´ã‚’ä¿å­˜"""
    with open(BACKUP_HISTORY_PATH, 'w') as f:
        json.dump(history, f, indent=2, ensure_ascii=False)


def create_backup(reason: str = "manual") -> str:
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’ä½œæˆ"""
    os.makedirs(BACKUP_DIR, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"backup_{timestamp}"
    backup_path = os.path.join(BACKUP_DIR, backup_name)

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    os.makedirs(backup_path, exist_ok=True)

    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
    import shutil
    backed_up = []
    for f in os.listdir(EMBEDDINGS_DIR):
        if f.endswith('.npy'):
            src = os.path.join(EMBEDDINGS_DIR, f)
            dst = os.path.join(backup_path, f)
            shutil.copy2(src, dst)
            backed_up.append(f)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚‚ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    if os.path.exists(DB_PATH):
        shutil.copy2(DB_PATH, os.path.join(backup_path, 'speaker_database.json'))

    # å±¥æ­´ã«è¿½åŠ 
    history = load_backup_history()
    history['backups'].append({
        'name': backup_name,
        'path': backup_path,
        'timestamp': datetime.now().isoformat(),
        'reason': reason,
        'files': backed_up,
    })

    # å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆæœ€å¤§æ•°ã‚’è¶…ãˆãŸå ´åˆï¼‰
    max_backups = history.get('max_backups', 10)
    while len(history['backups']) > max_backups:
        old_backup = history['backups'].pop(0)
        old_path = old_backup['path']
        if os.path.exists(old_path):
            shutil.rmtree(old_path)
            print(f"   ğŸ—‘ï¸ å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤: {old_backup['name']}")

    save_backup_history(history)

    print(f"   ğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_name} ({len(backed_up)}ãƒ•ã‚¡ã‚¤ãƒ«)")
    return backup_path


def list_backups() -> list:
    """åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§"""
    history = load_backup_history()
    return history.get('backups', [])


def restore_backup(backup_name: str = None) -> bool:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¾©å…ƒ"""
    history = load_backup_history()
    backups = history.get('backups', [])

    if not backups:
        print("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Šã¾ã›ã‚“")
        return False

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã¯æœ€æ–°ã‚’ä½¿ç”¨
    if backup_name is None:
        backup_info = backups[-1]
    else:
        backup_info = None
        for b in backups:
            if b['name'] == backup_name:
                backup_info = b
                break
        if not backup_info:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— '{backup_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

    backup_path = backup_info['path']
    if not os.path.exists(backup_path):
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {backup_path}")
        return False

    import shutil

    # ç¾åœ¨ã®çŠ¶æ…‹ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆå¾©å…ƒå‰ï¼‰
    create_backup(reason="pre_restore")

    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¾©å…ƒ
    restored = []
    for f in os.listdir(backup_path):
        if f.endswith('.npy'):
            src = os.path.join(backup_path, f)
            dst = os.path.join(EMBEDDINGS_DIR, f)
            shutil.copy2(src, dst)
            restored.append(f)

    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’å¾©å…ƒ
    db_backup = os.path.join(backup_path, 'speaker_database.json')
    if os.path.exists(db_backup):
        shutil.copy2(db_backup, DB_PATH)

    print(f"âœ… å¾©å…ƒå®Œäº†: {backup_info['name']}")
    print(f"   å¾©å…ƒãƒ•ã‚¡ã‚¤ãƒ«: {len(restored)}å€‹")
    print(f"   æ—¥æ™‚: {backup_info['timestamp']}")
    print(f"   ç†ç”±: {backup_info['reason']}")

    return True


def restore_player_embedding(player_name: str, backup_name: str = None) -> bool:
    """ç‰¹å®šé¸æ‰‹ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®ã¿å¾©å…ƒ"""
    history = load_backup_history()
    backups = history.get('backups', [])

    if not backups:
        print("âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãŒã‚ã‚Šã¾ã›ã‚“")
        return False

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é¸æŠ
    if backup_name is None:
        backup_info = backups[-1]
    else:
        backup_info = None
        for b in backups:
            if b['name'] == backup_name:
                backup_info = b
                break
        if not backup_info:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— '{backup_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False

    backup_path = backup_info['path']
    emb_file = f"{player_name.lower()}.npy"
    src = os.path.join(backup_path, emb_file)
    dst = os.path.join(EMBEDDINGS_DIR, emb_file)

    if not os.path.exists(src):
        print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã« {player_name} ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
        return False

    import shutil
    shutil.copy2(src, dst)

    print(f"âœ… {player_name} ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¾©å…ƒã—ã¾ã—ãŸ")
    print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {backup_info['name']} ({backup_info['timestamp']})")

    return True


def download_with_subtitles(url: str, output_dir: str) -> tuple:
    """å‹•ç”»ã¨å­—å¹•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    os.makedirs(output_dir, exist_ok=True)

    common_opts = {
        'quiet': True,
        'no_warnings': True,
        'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        },
    }

    try:
        # å‹•ç”»æƒ…å ±å–å¾—
        with yt_dlp.YoutubeDL(common_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            video_id = info.get('id')
            duration = info.get('duration', 0)

            if duration > 1800:  # 30åˆ†ä»¥ä¸Šã¯ã‚¹ã‚­ãƒƒãƒ—
                print(f"   âš ï¸ å‹•ç”»ãŒé•·ã™ãã¾ã™ ({duration}ç§’)")
                return None, None

        audio_path = os.path.join(output_dir, f"{video_id}.wav")
        sub_path = os.path.join(output_dir, f"{video_id}.ko.vtt")

        # æ—¢ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
        if os.path.exists(audio_path) and os.path.exists(sub_path):
            print(f"   â™»ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: {video_id}")
            return audio_path, sub_path

        # å­—å¹•ä»˜ãã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        ydl_opts = {
            **common_opts,
            'format': 'bestaudio[ext=m4a]/bestaudio/best',
            'outtmpl': os.path.join(output_dir, f"{video_id}.%(ext)s"),
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'wav',
            }],
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': ['ko', 'ko-KR', 'en'],
            'subtitlesformat': 'vtt',
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        # å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        for ext in ['.ko.vtt', '.ko-KR.vtt', '.en.vtt', '.vtt']:
            possible_sub = os.path.join(output_dir, f"{video_id}{ext}")
            if os.path.exists(possible_sub):
                sub_path = possible_sub
                break
        else:
            sub_path = None

        return audio_path, sub_path

    except Exception as e:
        print(f"   ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None, None


def parse_vtt_for_players(vtt_path: str) -> dict:
    """VTTå­—å¹•ã‚’è§£æã—ã¦é¸æ‰‹ã”ã¨ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º"""
    player_segments = {}

    if not vtt_path or not os.path.exists(vtt_path):
        return player_segments

    try:
        with open(vtt_path, 'r', encoding='utf-8') as f:
            content = f.read()

        # VTTã‚’ãƒ‘ãƒ¼ã‚¹
        # å½¢å¼: 00:00:00.000 --> 00:00:03.000
        #       [é¸æ‰‹å] ãƒ†ã‚­ã‚¹ãƒˆ
        time_pattern = r'(\d{2}:\d{2}:\d{2}\.\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2}\.\d{3})'

        lines = content.split('\n')
        current_start = None
        current_end = None

        for i, line in enumerate(lines):
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¡Œã‚’æ¤œå‡º
            time_match = re.search(time_pattern, line)
            if time_match:
                current_start = parse_timestamp(time_match.group(1))
                current_end = parse_timestamp(time_match.group(2))
                continue

            if current_start is None:
                continue

            # é¸æ‰‹åã‚’æ¤œå‡º
            # ãƒ‘ã‚¿ãƒ¼ãƒ³: [Faker], í˜ì´ì»¤:, Faker:, ã€Fakerã€‘ ãªã©
            for player_lower, aliases in PLAYER_NAME_KOREAN.items():
                for alias in aliases:
                    patterns = [
                        rf'\[{re.escape(alias)}\]',
                        rf'ã€{re.escape(alias)}ã€‘',
                        rf'{re.escape(alias)}\s*:',
                        rf'^{re.escape(alias)}\s*$',
                    ]
                    for pattern in patterns:
                        if re.search(pattern, line, re.IGNORECASE):
                            if player_lower not in player_segments:
                                player_segments[player_lower] = []
                            player_segments[player_lower].append({
                                'start': current_start,
                                'end': current_end,
                                'text': line.strip(),
                            })
                            break

        # é‡è¤‡ã‚’é™¤å»ã—ã¦ãƒãƒ¼ã‚¸
        for player in player_segments:
            player_segments[player] = merge_segments(player_segments[player])

        return player_segments

    except Exception as e:
        print(f"   å­—å¹•è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return {}


def parse_timestamp(ts: str) -> float:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç§’ã«å¤‰æ›"""
    parts = ts.replace(',', '.').split(':')
    if len(parts) == 3:
        h, m, s = parts
        return float(h) * 3600 + float(m) * 60 + float(s)
    elif len(parts) == 2:
        m, s = parts
        return float(m) * 60 + float(s)
    return 0


def merge_segments(segments: list, gap: float = 1.0) -> list:
    """è¿‘æ¥ã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒãƒ¼ã‚¸"""
    if not segments:
        return []

    sorted_segs = sorted(segments, key=lambda x: x['start'])
    merged = [sorted_segs[0].copy()]

    for seg in sorted_segs[1:]:
        if seg['start'] - merged[-1]['end'] < gap:
            merged[-1]['end'] = max(merged[-1]['end'], seg['end'])
        else:
            merged.append(seg.copy())

    return merged


def load_existing_embeddings(team_name: str = None) -> dict:
    """æ—¢å­˜ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿"""
    embeddings = {}
    db = load_database()

    for player_name, info in db.get('players', {}).items():
        # ãƒãƒ¼ãƒ æŒ‡å®šãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if team_name and info.get('team') != team_name:
            continue

        emb_file = info.get('embedding_file')
        if emb_file:
            emb_path = os.path.join(EMBEDDINGS_DIR, emb_file)
            if os.path.exists(emb_path):
                emb = np.load(emb_path)
                if len(emb.shape) == 1 and emb.shape[0] == 192:
                    embeddings[player_name.lower()] = {
                        'embedding': emb,
                        'name': player_name,
                        'team': info.get('team'),
                    }
    return embeddings


def identify_speaker(embedding: np.ndarray, known_embeddings: dict,
                     threshold: float = 0.4) -> tuple:
    """ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ—¢çŸ¥ã®é¸æ‰‹ã¨ç…§åˆ"""
    best_match = None
    best_score = -1

    for player, info in known_embeddings.items():
        known_emb = info['embedding']
        # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦
        score = np.dot(embedding, known_emb) / (
            np.linalg.norm(embedding) * np.linalg.norm(known_emb)
        )
        if score > best_score:
            best_score = score
            best_match = info['name']

    if best_score >= threshold:
        return best_match, best_score
    return None, best_score


def collect_with_diarization(team_name: str, target_player: str = None,
                             max_videos: int = 3, update_embedding: bool = True,
                             similarity_threshold: float = 0.45) -> dict:
    """è©±è€…ãƒ€ã‚¤ã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ + æ—¢å­˜ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ç…§åˆã«ã‚ˆã‚‹åé›†ï¼ˆæ¨å¥¨ï¼‰"""
    print(f"\n{'='*60}")
    print(f"ğŸ¯ {team_name} ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹ã‹ã‚‰è©±è€…ç…§åˆã§åé›†")
    print(f"{'='*60}")

    if target_player:
        print(f"   å¯¾è±¡é¸æ‰‹: {target_player}")
    print(f"   é¡ä¼¼åº¦é–¾å€¤: {similarity_threshold}")

    keywords = TEAM_VOICE_KEYWORDS.get(team_name, [f"{team_name} team voice LCK"])
    team_dir = os.path.join(COLLECT_DIR, f"diarize_{team_name.lower()}")
    os.makedirs(team_dir, exist_ok=True)

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
    encoder = EncoderClassifier.from_hparams(
        source='speechbrain/spkrec-ecapa-voxceleb',
        savedir=CACHE_DIR
    )

    # æ—¢å­˜ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿
    print("\nğŸ“‚ æ—¢å­˜ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    known_embeddings = load_existing_embeddings(team_name)
    print(f"   {len(known_embeddings)}é¸æ‰‹ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’èª­ã¿è¾¼ã¿")

    if not known_embeddings:
        print("   âš ï¸ æ—¢å­˜ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ãŒã‚ã‚Šã¾ã›ã‚“")
        return {}

    # åé›†çµæœ
    collected = {}
    processed_videos = []

    for keyword in keywords[:2]:
        print(f"\nğŸ” æ¤œç´¢: {keyword}")
        videos = search_youtube(keyword, max_results=max_videos)

        for video in videos:
            if video['id'] in processed_videos:
                continue

            print(f"\nğŸ“¹ {video['title'][:60]}...")
            print(f"   URL: {video['url']}")

            # éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            audio_path = download_audio(video['url'], team_dir)
            if not audio_path:
                continue

            processed_videos.append(video['id'])

            # Whisperã§ç™ºè©±åŒºé–“æ¤œå‡º
            print("   ğŸ™ï¸ ç™ºè©±åŒºé–“æ¤œå‡ºä¸­...")
            segments = detect_speech_segments(audio_path, min_speech_duration=2.0)
            print(f"   æ¤œå‡º: {len(segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

            # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æ—¢çŸ¥é¸æ‰‹ã¨ç…§åˆ
            print("   ğŸ” è©±è€…ç…§åˆä¸­...")
            matched_count = 0

            for seg in segments[:30]:  # æœ€å¤§30ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                emb = extract_embedding(audio_path, seg['start'], seg['end'], encoder)
                if emb is None:
                    continue

                # æ—¢çŸ¥é¸æ‰‹ã¨ç…§åˆ
                matched_player, score = identify_speaker(
                    emb, known_embeddings, threshold=similarity_threshold
                )

                if matched_player:
                    player_lower = matched_player.lower()

                    # å¯¾è±¡é¸æ‰‹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    if target_player and player_lower != target_player.lower():
                        continue

                    if player_lower not in collected:
                        collected[player_lower] = []

                    collected[player_lower].append({
                        'embedding': emb,
                        'video_id': video['id'],
                        'start': seg['start'],
                        'end': seg['end'],
                        'score': score,
                        'text': seg.get('text', ''),
                    })
                    matched_count += 1

            print(f"   âœ… {matched_count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ç…§åˆ")

            # é¸æ‰‹ã”ã¨ã®çµæœ
            for player, segs in collected.items():
                recent = [s for s in segs if s['video_id'] == video['id']]
                if recent:
                    avg_score = sum(s['score'] for s in recent) / len(recent)
                    print(f"      {player}: {len(recent)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ (å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f})")

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"ğŸ“Š åé›†çµæœã‚µãƒãƒªãƒ¼")
    print(f"{'='*60}")

    results = {}
    for player, segments in collected.items():
        count = len(segments)
        avg_score = sum(s['score'] for s in segments) / count if count > 0 else 0
        results[player] = {'count': count, 'avg_score': avg_score}
        print(f"   {player}: {count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ (å¹³å‡ã‚¹ã‚³ã‚¢: {avg_score:.3f})")

        # é«˜ã‚¹ã‚³ã‚¢ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®ã¿ã§ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°
        if update_embedding and count >= 3:
            # ã‚¹ã‚³ã‚¢ã§ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½ã‚’ä½¿ç”¨
            high_quality = sorted(segments, key=lambda x: x['score'], reverse=True)
            top_segments = high_quality[:min(10, count)]
            min_score = min(s['score'] for s in top_segments)

            if min_score >= similarity_threshold:
                print(f"   ğŸ”„ {player}ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°ä¸­...")
                print(f"      ä½¿ç”¨ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {len(top_segments)} (ã‚¹ã‚³ã‚¢ {min_score:.3f}ã€œ{top_segments[0]['score']:.3f})")

                embeddings = [seg['embedding'] for seg in top_segments]
                success = update_player_embedding(player.capitalize(), embeddings, weight_new=0.15)

                if success:
                    print(f"   âœ… {player}ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸ")

                    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
                    db = load_database()
                    player_cap = player.capitalize()
                    if player_cap in db.get('players', {}):
                        old_acc = db['players'][player_cap].get('accuracy', {})
                        db['players'][player_cap]['accuracy'] = {
                            'max': float(max(old_acc.get('max', 0), top_segments[0]['score'])),
                            'avg': float((old_acc.get('avg', 0) + avg_score) / 2),
                            'level': 'high' if avg_score >= 0.5 else 'medium' if avg_score >= 0.35 else 'low',
                            'source': 'diarization_matched',
                            'collected_segments': count,
                        }
                        save_database(db)
            else:
                print(f"   âš ï¸ {player}: ã‚¹ã‚³ã‚¢ãŒä½ã„ãŸã‚æ›´æ–°ã‚’ã‚¹ã‚­ãƒƒãƒ—")

    if not results:
        print("   âš ï¸ é¸æ‰‹éŸ³å£°ã‚’åé›†ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    return results


def collect_from_team_voice(team_name: str, target_player: str = None,
                            max_videos: int = 5, update_embedding: bool = True) -> dict:
    """ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‹ã‚‰é¸æ‰‹éŸ³å£°ã‚’è‡ªå‹•åé›†ï¼ˆæ¨å¥¨æ–¹å¼ï¼‰"""
    print(f"\n{'='*60}")
    print(f"ğŸ® {team_name} ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‹ã‚‰è‡ªå‹•åé›†")
    print(f"{'='*60}")

    if target_player:
        print(f"   å¯¾è±¡é¸æ‰‹: {target_player}")

    keywords = TEAM_VOICE_KEYWORDS.get(team_name, [f"{team_name} team voice LCK"])
    team_dir = os.path.join(COLLECT_DIR, f"team_voice_{team_name.lower()}")
    os.makedirs(team_dir, exist_ok=True)

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
    encoder = EncoderClassifier.from_hparams(
        source='speechbrain/spkrec-ecapa-voxceleb',
        savedir=CACHE_DIR
    )

    # é¸æ‰‹ã”ã¨ã®åé›†çµæœ
    collected = {}
    processed_videos = []

    for keyword in keywords[:2]:  # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯2ã¤ã¾ã§
        print(f"\nğŸ” æ¤œç´¢: {keyword}")
        videos = search_youtube(keyword, max_results=max_videos)

        for video in videos:
            if video['id'] in processed_videos:
                continue

            print(f"\nğŸ“¹ {video['title'][:60]}...")
            print(f"   URL: {video['url']}")

            # éŸ³å£°ã¨å­—å¹•ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            print("   ğŸ“¥ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­...")
            audio_path, sub_path = download_with_subtitles(video['url'], team_dir)

            if not audio_path:
                continue

            processed_videos.append(video['id'])

            # å­—å¹•ã‹ã‚‰é¸æ‰‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º
            if sub_path:
                print(f"   ğŸ“ å­—å¹•è§£æä¸­...")
                player_segments = parse_vtt_for_players(sub_path)

                if player_segments:
                    print(f"   æ¤œå‡ºã•ã‚ŒãŸé¸æ‰‹: {', '.join(player_segments.keys())}")

                    for player, segments in player_segments.items():
                        # å¯¾è±¡é¸æ‰‹ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        if target_player and player != target_player.lower():
                            continue

                        if player not in collected:
                            collected[player] = []

                        # å„ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æŠ½å‡º
                        for seg in segments[:15]:  # å‹•ç”»ã‚ãŸã‚Šæœ€å¤§15ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                            if seg['end'] - seg['start'] < 1.5:  # 1.5ç§’ä»¥ä¸Š
                                continue

                            emb = extract_embedding(
                                audio_path, seg['start'], seg['end'], encoder
                            )
                            if emb is not None:
                                collected[player].append({
                                    'embedding': emb,
                                    'video_id': video['id'],
                                    'start': seg['start'],
                                    'end': seg['end'],
                                })

                        print(f"      {player}: {len(collected.get(player, []))}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
                else:
                    print("   âš ï¸ å­—å¹•ã‹ã‚‰é¸æ‰‹åãŒæ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    # å­—å¹•ãªã—ã®å ´åˆã¯Whisperã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    print("   ğŸ™ï¸ Whisperã§ç™ºè©±æ¤œå‡º...")
                    segments = detect_speech_segments(audio_path)
                    print(f"   âš ï¸ {len(segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¤œå‡ºï¼ˆé¸æ‰‹ä¸æ˜ï¼‰")
            else:
                print("   âš ï¸ å­—å¹•ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\n{'='*60}")
    print(f"ğŸ“Š åé›†çµæœã‚µãƒãƒªãƒ¼")
    print(f"{'='*60}")

    results = {}
    for player, segments in collected.items():
        count = len(segments)
        results[player] = count
        print(f"   {player}: {count}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°
        if update_embedding and count >= 3:  # 3ã‚»ã‚°ãƒ¡ãƒ³ãƒˆä»¥ä¸Šã§æ›´æ–°
            print(f"   ğŸ”„ {player}ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°ä¸­...")
            embeddings = [seg['embedding'] for seg in segments]
            success = update_player_embedding(player.capitalize(), embeddings)

            if success:
                print(f"   âœ… {player}ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸ")

                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
                db = load_database()
                player_cap = player.capitalize()
                if player_cap in db.get('players', {}):
                    db['players'][player_cap]['accuracy']['source'] = 'team_voice'
                    db['players'][player_cap]['accuracy']['collected_segments'] = count
                    save_database(db)

    if not results:
        print("   âš ï¸ é¸æ‰‹éŸ³å£°ã‚’åé›†ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        print("   ğŸ’¡ å­—å¹•ä»˜ãã®ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‚’æ¢ã—ã¦ãã ã•ã„")

    return results


def search_youtube(query: str, max_results: int = 5) -> list:
    """YouTubeã§å‹•ç”»ã‚’æ¤œç´¢"""
    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True,
        'default_search': 'ytsearch',
    }

    search_query = f"ytsearch{max_results}:{query}"

    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            result = ydl.extract_info(search_query, download=False)
            if 'entries' in result:
                videos = []
                for entry in result['entries']:
                    if entry:
                        videos.append({
                            'id': entry.get('id'),
                            'title': entry.get('title'),
                            'url': f"https://www.youtube.com/watch?v={entry.get('id')}",
                            'duration': entry.get('duration', 0),
                        })
                return videos
    except Exception as e:
        print(f"   æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")

    return []


def download_audio(url: str, output_dir: str, max_duration: int = 1800) -> str:
    """YouTubeå‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    os.makedirs(output_dir, exist_ok=True)

    # å…±é€šã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆ403ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
    common_opts = {
        'quiet': True,
        'no_warnings': True,
        'extractor_args': {'youtube': {'player_client': ['android', 'web']}},
        'http_headers': {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        },
    }

    try:
        # å‹•ç”»æƒ…å ±ã‚’å–å¾—
        with yt_dlp.YoutubeDL(common_opts) as ydl:
            info = ydl.extract_info(url, download=False)
            duration = info.get('duration', 0)
            video_id = info.get('id')
            title = info.get('title', 'unknown')

            # é•·ã™ãã‚‹å‹•ç”»ã¯ã‚¹ã‚­ãƒƒãƒ—
            if duration > max_duration:
                print(f"   âš ï¸ å‹•ç”»ãŒé•·ã™ãã¾ã™ ({duration}ç§’ > {max_duration}ç§’)")
                return None

        # éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        audio_path = os.path.join(output_dir, f"{video_id}.wav")

        if os.path.exists(audio_path):
            print(f"   â™»ï¸ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨: {video_id}")
            return audio_path

        ydl_opts = {
            **common_opts,
            'format': 'bestaudio[ext=m4a]/bestaudio/best',
            'outtmpl': os.path.join(output_dir, f"{video_id}.%(ext)s"),
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'wav',
            }],
        }

        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])

        return audio_path

    except Exception as e:
        print(f"   ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def detect_speech_segments(audio_path: str, min_speech_duration: float = 2.0) -> list:
    """éŸ³å£°ã‹ã‚‰ç™ºè©±åŒºé–“ã‚’æ¤œå‡ºï¼ˆWhisperãƒ™ãƒ¼ã‚¹ï¼‰"""
    try:
        model = whisper.load_model("base")
        result = model.transcribe(audio_path, language="ko")

        segments = []
        for seg in result['segments']:
            duration = seg['end'] - seg['start']
            if duration >= min_speech_duration:
                segments.append({
                    'start': seg['start'],
                    'end': seg['end'],
                    'text': seg['text'].strip(),
                    'duration': duration,
                })

        return segments

    except Exception as e:
        print(f"   ç™ºè©±æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return []


def extract_embedding(audio_path: str, start: float, end: float, encoder) -> np.ndarray:
    """éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‹ã‚‰ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æŠ½å‡º"""
    try:
        waveform, sr = torchaudio.load(audio_path)

        # ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›
        if waveform.shape[0] > 1:
            waveform = waveform.mean(dim=0, keepdim=True)

        # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆ16kHzï¼‰
        if sr != 16000:
            resampler = torchaudio.transforms.Resample(sr, 16000)
            waveform = resampler(waveform)
            sr = 16000

        start_sample = int(start * sr)
        end_sample = int(end * sr)

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæŠ½å‡º
        segment = waveform[:, start_sample:end_sample]

        if segment.shape[1] < sr:  # 1ç§’æœªæº€ã¯ã‚¹ã‚­ãƒƒãƒ—
            return None

        # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°è¨ˆç®—
        emb = encoder.encode_batch(segment).squeeze().numpy()

        # å½¢çŠ¶ç¢ºèªï¼ˆ192,ï¼‰ã§ã‚ã‚‹ã¹ã
        if len(emb.shape) != 1 or emb.shape[0] != 192:
            print(f"   âš ï¸ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°å½¢çŠ¶ç•°å¸¸: {emb.shape}")
            return None

        return emb

    except Exception as e:
        print(f"   ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
        return None


# ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ãƒ©ã‚°ï¼ˆåŒä¸€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã§è¤‡æ•°å›ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’é¿ã‘ã‚‹ï¼‰
_session_backup_created = False


def update_player_embedding(player_name: str, new_embeddings: list, weight_new: float = 0.2,
                            auto_backup: bool = True):
    """é¸æ‰‹ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°ï¼ˆè‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰"""
    global _session_backup_created

    if not new_embeddings:
        return False

    emb_path = os.path.join(EMBEDDINGS_DIR, f'{player_name.lower()}.npy')

    # æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³æœ€åˆã®æ›´æ–°å‰ã«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
    if auto_backup and os.path.exists(emb_path) and not _session_backup_created:
        print("   ğŸ’¾ æ›´æ–°å‰ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
        create_backup(reason="auto_before_update")
        _session_backup_created = True

    # æ–°ã—ã„ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã®å¹³å‡
    new_emb = np.mean(new_embeddings, axis=0)

    if os.path.exists(emb_path):
        existing = np.load(emb_path)
        # é‡ã¿ä»˜ã‘çµåˆ
        combined = (1 - weight_new) * existing + weight_new * new_emb
        combined = combined / np.linalg.norm(combined) * np.linalg.norm(existing)
    else:
        combined = new_emb

    np.save(emb_path, combined)
    return True


def reset_session_backup_flag():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    global _session_backup_created
    _session_backup_created = False


def collect_player_voice(player_name: str, max_videos: int = 3,
                         update_embedding: bool = True) -> dict:
    """é¸æ‰‹ã®éŸ³å£°ã‚’åé›†ã—ã¦ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°"""
    player_lower = player_name.lower()
    player_dir = os.path.join(COLLECT_DIR, player_lower)
    os.makedirs(player_dir, exist_ok=True)

    print(f"\n{'='*50}")
    print(f"ğŸ¤ {player_name} ã®éŸ³å£°åé›†")
    print(f"{'='*50}")

    # æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å–å¾—
    keywords = PLAYER_SEARCH_KEYWORDS.get(player_lower, [f"{player_name} interview"])

    collected_segments = []
    processed_videos = []

    # ã‚¨ãƒ³ã‚³ãƒ¼ãƒ€ãƒ¼åˆæœŸåŒ–
    encoder = EncoderClassifier.from_hparams(
        source='speechbrain/spkrec-ecapa-voxceleb',
        savedir=CACHE_DIR
    )

    for keyword in keywords:
        print(f"\nğŸ” æ¤œç´¢: {keyword}")
        videos = search_youtube(keyword, max_results=max_videos)

        for video in videos:
            if video['id'] in processed_videos:
                continue

            print(f"\nğŸ“¹ {video['title'][:50]}...")
            print(f"   URL: {video['url']}")

            # éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            audio_path = download_audio(video['url'], player_dir)
            if not audio_path:
                continue

            # ç™ºè©±åŒºé–“æ¤œå‡º
            print("   ğŸ™ï¸ ç™ºè©±åŒºé–“æ¤œå‡ºä¸­...")
            segments = detect_speech_segments(audio_path)
            print(f"   æ¤œå‡º: {len(segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

            # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æŠ½å‡º
            for seg in segments[:10]:  # æœ€å¤§10ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ
                emb = extract_embedding(audio_path, seg['start'], seg['end'], encoder)
                if emb is not None:
                    collected_segments.append({
                        'embedding': emb,
                        'text': seg['text'],
                        'video_id': video['id'],
                        'start': seg['start'],
                        'end': seg['end'],
                    })

            processed_videos.append(video['id'])

            if len(collected_segments) >= 20:  # ååˆ†ãªã‚»ã‚°ãƒ¡ãƒ³ãƒˆãŒé›†ã¾ã£ãŸã‚‰çµ‚äº†
                break

        if len(collected_segments) >= 20:
            break

    print(f"\nğŸ“Š åé›†çµæœ: {len(collected_segments)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")

    # ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°
    if update_embedding and collected_segments:
        print("\nğŸ”„ ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°ä¸­...")
        embeddings = [seg['embedding'] for seg in collected_segments]
        success = update_player_embedding(player_name, embeddings)

        if success:
            print(f"âœ… {player_name}ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ›´æ–°ã—ã¾ã—ãŸ")

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ›´æ–°
            db = load_database()
            if player_name in db.get('players', {}):
                db['players'][player_name]['accuracy']['source'] = 'auto_collected'
                db['players'][player_name]['accuracy']['collected_segments'] = len(collected_segments)
                save_database(db)

    return {
        'player': player_name,
        'segments_collected': len(collected_segments),
        'videos_processed': len(processed_videos),
        'segments': collected_segments,
    }


def collect_team_voices(team_name: str, **kwargs):
    """ãƒãƒ¼ãƒ å…¨å“¡ã®éŸ³å£°ã‚’åé›†"""
    db = load_database()

    if team_name not in db.get('teams', {}):
        print(f"âŒ ãƒãƒ¼ãƒ  {team_name} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return

    players = db['teams'][team_name]['players']

    print(f"\n{'='*50}")
    print(f"ğŸ† {team_name} å…¨é¸æ‰‹ã®éŸ³å£°åé›†")
    print(f"{'='*50}")
    print(f"é¸æ‰‹: {', '.join(players)}")

    results = []
    for player in players:
        result = collect_player_voice(player, **kwargs)
        results.append(result)

    # ã‚µãƒãƒªãƒ¼
    print(f"\n{'='*50}")
    print(f"ğŸ“Š {team_name} åé›†ã‚µãƒãƒªãƒ¼")
    print(f"{'='*50}")
    for r in results:
        status = "âœ…" if r['segments_collected'] > 0 else "âŒ"
        print(f"  {status} {r['player']}: {r['segments_collected']}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")


def collect_team_voice_videos(team_name: str, max_videos: int = 3):
    """ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’åé›†"""
    print(f"\n{'='*50}")
    print(f"ğŸ® {team_name} ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»åé›†")
    print(f"{'='*50}")

    keywords = TEAM_VOICE_KEYWORDS.get(team_name, [f"{team_name} team voice"])
    team_dir = os.path.join(COLLECT_DIR, f"team_voice_{team_name.lower()}")
    os.makedirs(team_dir, exist_ok=True)

    for keyword in keywords:
        print(f"\nğŸ” æ¤œç´¢: {keyword}")
        videos = search_youtube(keyword, max_results=max_videos)

        for video in videos:
            print(f"\nğŸ“¹ {video['title'][:50]}...")
            print(f"   URL: {video['url']}")
            print(f"   âš ï¸ ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã¯æ‰‹å‹•ã§ãƒ©ãƒ™ãƒªãƒ³ã‚°ãŒå¿…è¦ã§ã™")
            print(f"   ã‚³ãƒãƒ³ãƒ‰ä¾‹: python clip_with_speaker.py '{video['url']}' 0:00 1:00 --learn")


def main():
    parser = argparse.ArgumentParser(description='é¸æ‰‹ã®éŸ³å£°ã‚’è‡ªå‹•åé›†')
    parser.add_argument('player', nargs='?', help='é¸æ‰‹å')
    parser.add_argument('--team', '-t', help='ãƒãƒ¼ãƒ å…¨å“¡ã‚’åé›†ï¼ˆã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼å‹•ç”»ï¼‰')
    parser.add_argument('--team-voice-auto', '-tva', help='ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‹ã‚‰è‡ªå‹•åé›†ï¼ˆå­—å¹•ãƒ™ãƒ¼ã‚¹ï¼‰')
    parser.add_argument('--diarize', '-d', help='è©±è€…ç…§åˆã§åé›†ï¼ˆæ¨å¥¨ãƒ»æœ€ã‚‚ç²¾åº¦ãŒé«˜ã„ï¼‰')
    parser.add_argument('--player', '-p', dest='target_player', help='å¯¾è±¡é¸æ‰‹ï¼ˆ--team-voice-autoã¨ä½µç”¨ï¼‰')
    parser.add_argument('--all', '-a', action='store_true', help='å…¨é¸æ‰‹ã‚’åé›†')
    parser.add_argument('--team-voice', '-tv', help='ãƒãƒ¼ãƒ ãƒœã‚¤ã‚¹å‹•ç”»ã‚’æ¤œç´¢ï¼ˆæ‰‹å‹•ç”¨ï¼‰')
    parser.add_argument('--max-videos', '-m', type=int, default=5, help='æ¤œç´¢ã™ã‚‹å‹•ç”»æ•°')
    parser.add_argument('--collect-only', action='store_true', help='åé›†ã®ã¿ï¼ˆæ›´æ–°ãªã—ï¼‰')
    parser.add_argument('--list', '-l', action='store_true', help='ç™»éŒ²é¸æ‰‹ä¸€è¦§')

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/å¾©å…ƒã‚ªãƒ—ã‚·ãƒ§ãƒ³
    parser.add_argument('--backup', '-b', action='store_true', help='ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—')
    parser.add_argument('--restore', '-r', nargs='?', const='latest', help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒï¼ˆåå‰æŒ‡å®šå¯ï¼‰')
    parser.add_argument('--restore-player', help='ç‰¹å®šé¸æ‰‹ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¾©å…ƒ')
    parser.add_argument('--list-backups', action='store_true', help='ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ã‚’è¡¨ç¤º')

    args = parser.parse_args()

    if args.list:
        db = load_database()
        print("\nç™»éŒ²é¸æ‰‹ä¸€è¦§:")
        for team, info in db.get('teams', {}).items():
            print(f"\nã€{team}ã€‘")
            for player in info['players']:
                player_info = db.get('players', {}).get(player, {})
                acc = player_info.get('accuracy', {})
                level = acc.get('level', 'unknown')
                print(f"  - {player} ({level})")
        return

    if args.list_backups:
        backups = list_backups()
        if not backups:
            print("\nğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¯ã‚ã‚Šã¾ã›ã‚“")
        else:
            print(f"\nğŸ’¾ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ ({len(backups)}ä»¶)")
            print("=" * 60)
            for i, b in enumerate(backups):
                print(f"  [{i+1}] {b['name']}")
                print(f"      æ—¥æ™‚: {b['timestamp']}")
                print(f"      ç†ç”±: {b['reason']}")
                print(f"      ãƒ•ã‚¡ã‚¤ãƒ«: {len(b.get('files', []))}å€‹")
        return

    if args.backup:
        print("\nğŸ’¾ æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
        create_backup(reason="manual")
        print("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†")
        return

    if args.restore:
        backup_name = None if args.restore == 'latest' else args.restore
        print(f"\nğŸ”„ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒä¸­...")
        if backup_name:
            print(f"   å¯¾è±¡: {backup_name}")
        else:
            print("   å¯¾è±¡: æœ€æ–°ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
        restore_backup(backup_name)
        return

    if args.restore_player:
        print(f"\nğŸ”„ {args.restore_player} ã®ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã‚’å¾©å…ƒä¸­...")
        restore_player_embedding(args.restore_player)
        return

    if args.diarize:
        collect_with_diarization(
            args.diarize,
            target_player=args.target_player,
            max_videos=args.max_videos,
            update_embedding=not args.collect_only
        )
        return

    if args.team_voice_auto:
        collect_from_team_voice(
            args.team_voice_auto,
            target_player=args.target_player,
            max_videos=args.max_videos,
            update_embedding=not args.collect_only
        )
        return

    if args.team_voice:
        collect_team_voice_videos(args.team_voice, max_videos=args.max_videos)
        return

    if args.team:
        collect_team_voices(
            args.team,
            max_videos=args.max_videos,
            update_embedding=not args.collect_only
        )
        return

    if args.all:
        db = load_database()
        for team in db.get('teams', {}).keys():
            collect_team_voices(
                team,
                max_videos=args.max_videos,
                update_embedding=not args.collect_only
            )
        return

    if args.player:
        collect_player_voice(
            args.player,
            max_videos=args.max_videos,
            update_embedding=not args.collect_only
        )
        return

    parser.print_help()
    print("\nä½¿ç”¨ä¾‹:")
    print("  # ã€æœ€æ¨å¥¨ã€‘è©±è€…ç…§åˆã§åé›†ï¼ˆæ—¢å­˜ã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°ã¨ç…§åˆï¼‰")
    print("  python auto_collect_voice.py --diarize T1")
    print()
    print("  # ç‰¹å®šé¸æ‰‹ã®ã¿åé›†")
    print("  python auto_collect_voice.py --diarize T1 --player Faker")
    print()
    print("  # åé›†ã®ã¿ï¼ˆã‚¨ãƒ³ãƒ™ãƒ‡ã‚£ãƒ³ã‚°æ›´æ–°ãªã—ï¼‰")
    print("  python auto_collect_voice.py --diarize T1 --collect-only")
    print()
    print("  # ç™»éŒ²é¸æ‰‹ä¸€è¦§")
    print("  python auto_collect_voice.py --list")
    print()
    print("  # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—/å¾©å…ƒ")
    print("  python auto_collect_voice.py --backup              # æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—")
    print("  python auto_collect_voice.py --list-backups        # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§")
    print("  python auto_collect_voice.py --restore             # æœ€æ–°ã‹ã‚‰å¾©å…ƒ")
    print("  python auto_collect_voice.py --restore backup_xxx  # æŒ‡å®šã‹ã‚‰å¾©å…ƒ")
    print("  python auto_collect_voice.py --restore-player Faker # ç‰¹å®šé¸æ‰‹ã®ã¿å¾©å…ƒ")


if __name__ == "__main__":
    main()
